# TechTrack Model Analysis: YOLOv4-Tiny Object Detection Performance

## Executive Summary

This analysis compares two YOLOv4-tiny model variants for logistics and safety monitoring applications, evaluating detection performance across 20 object classes. **YOLOv4-tiny2** achieves superior overall performance (mAP@0.5: 0.589 vs 0.532), though model selection depends on specific class priorities. The analysis also quantifies the impact of data augmentation and hard negative mining strategies on model robustness.

> **Note**: Visualization images referenced in this document are generated by running the evaluation scripts (`viz_metrics.py`, `F1_Curve_and_confusion_matrix.py`). These outputs are gitignored due to size but can be regenerated from the raw metrics data.

---

## 1. Model Comparison: YOLOv4-Tiny1 vs YOLOv4-Tiny2

### Evaluation Metrics

Three complementary metrics were used for comprehensive model assessment:

| Metric | Purpose | Interpretation |
|--------|---------|----------------|
| **Average Precision (AP@0.5)** | Primary detection metric | Summarizes precision-recall curve; accounts for localization quality |
| **F1-Score@0.5** | Balance metric | Harmonic mean of precision and recall at fixed confidence |
| **ROC-AUC** | Ranking quality | Measures how well positives score above negatives across thresholds |

### Per-Class Performance Results

| Model | Class | AP@0.5 | Precision@0.5 | Recall@0.5 | F1@0.5 | ROC-AUC |
|:------|:------|-------:|-------------:|----------:|-------:|--------:|
| yolov4-tiny1 | barcode | 0.465 | 0.881 | 0.489 | 0.629 | 0.744 |
| yolov4-tiny1 | car | 0.720 | 0.602 | 0.808 | 0.690 | 0.887 |
| yolov4-tiny1 | cardboard box | 0.632 | 0.839 | 0.634 | 0.722 | 0.816 |
| yolov4-tiny1 | fire | 0.217 | 0.957 | 0.117 | 0.209 | 0.558 |
| yolov4-tiny1 | forklift | 0.534 | 0.957 | 0.497 | 0.655 | 0.748 |
| yolov4-tiny1 | freight container | 0.283 | 0.782 | 0.318 | 0.452 | 0.658 |
| yolov4-tiny1 | gloves | 0.512 | 0.914 | 0.518 | 0.661 | 0.758 |
| yolov4-tiny1 | helmet | 0.669 | 0.899 | 0.666 | 0.765 | 0.831 |
| yolov4-tiny1 | ladder | 0.215 | 0.800 | 0.219 | 0.343 | 0.609 |
| yolov4-tiny1 | license plate | 0.330 | 0.841 | 0.325 | 0.469 | 0.662 |
| yolov4-tiny1 | person | 0.609 | 0.907 | 0.541 | 0.677 | 0.765 |
| yolov4-tiny1 | qr code | 0.820 | 0.891 | 0.876 | 0.884 | 0.937 |
| yolov4-tiny1 | road sign | 0.223 | 0.709 | 0.223 | 0.339 | 0.610 |
| yolov4-tiny1 | safety vest | 0.618 | 0.917 | 0.620 | 0.740 | 0.809 |
| yolov4-tiny1 | smoke | 0.275 | 1.000 | 0.193 | 0.323 | 0.596 |
| yolov4-tiny1 | traffic cone | 0.803 | 0.887 | 0.811 | 0.847 | 0.905 |
| yolov4-tiny1 | traffic light | 0.728 | 0.976 | 0.710 | 0.822 | 0.854 |
| yolov4-tiny1 | truck | 0.560 | 0.895 | 0.567 | 0.694 | 0.781 |
| yolov4-tiny1 | van | 0.672 | 0.706 | 0.742 | 0.724 | 0.863 |
| yolov4-tiny1 | wood pallet | 0.746 | 0.927 | 0.750 | 0.829 | 0.874 |
| yolov4-tiny2 | barcode | 0.381 | 0.914 | 0.390 | 0.546 | 0.694 |
| yolov4-tiny2 | car | 0.726 | 0.669 | 0.792 | 0.726 | 0.883 |
| yolov4-tiny2 | cardboard box | 0.703 | 0.548 | 0.756 | 0.636 | 0.871 |
| yolov4-tiny2 | fire | 0.307 | 0.976 | 0.217 | 0.355 | 0.608 |
| yolov4-tiny2 | forklift | 0.753 | 0.892 | 0.759 | 0.820 | 0.876 |
| yolov4-tiny2 | freight container | 0.326 | 0.805 | 0.365 | 0.502 | 0.681 |
| yolov4-tiny2 | gloves | 0.560 | 0.969 | 0.553 | 0.704 | 0.776 |
| yolov4-tiny2 | helmet | 0.716 | 0.894 | 0.724 | 0.800 | 0.860 |
| yolov4-tiny2 | ladder | 0.365 | 0.886 | 0.383 | 0.534 | 0.691 |
| yolov4-tiny2 | license plate | 0.373 | 0.880 | 0.377 | 0.528 | 0.688 |
| yolov4-tiny2 | person | 0.701 | 0.889 | 0.665 | 0.761 | 0.825 |
| yolov4-tiny2 | qr code | 0.823 | 0.919 | 0.870 | 0.893 | 0.934 |
| yolov4-tiny2 | road sign | 0.209 | 0.475 | 0.261 | 0.337 | 0.625 |
| yolov4-tiny2 | safety vest | 0.702 | 0.926 | 0.708 | 0.802 | 0.853 |
| yolov4-tiny2 | smoke | 0.353 | 0.979 | 0.281 | 0.437 | 0.640 |
| yolov4-tiny2 | traffic cone | 0.776 | 0.924 | 0.790 | 0.852 | 0.895 |
| yolov4-tiny2 | traffic light | 0.737 | 0.980 | 0.721 | 0.830 | 0.860 |
| yolov4-tiny2 | truck | 0.732 | 0.756 | 0.803 | 0.779 | 0.895 |
| yolov4-tiny2 | van | 0.751 | 0.693 | 0.833 | 0.757 | 0.909 |
| yolov4-tiny2 | wood pallet | 0.788 | 0.946 | 0.791 | 0.862 | 0.894 |

### Visual Comparisons

*The following visualizations can be generated by running `python modules/viz_metrics.py`:*

<!-- Generated images (run viz_metrics.py to create):
- modules/per_class_AP_with_mAP.png - Figure 1: Average Precision per class with overall mAP comparison
- modules/per_class_F1.png - Figure 2: F1-Score per class at confidence threshold 0.5
- modules/per_class_ROC_AUC.png - Figure 3: ROC-AUC per class comparison
-->

---

## 2. Class-Level Model Selection Analysis

### Average Precision Comparison

For object detection, AP@0.5 is the primary metric as it accounts for both classification and localization quality.

| Class | AP Tiny1 | AP Tiny2 | Δ (Tiny2 – Tiny1) | Best Model |
|:------|:---------|:---------|:------------------|:-----------|
| barcode | 0.465 | 0.381 | -0.084 | **Tiny1** |
| car | 0.720 | 0.726 | +0.006 | Tiny2 |
| cardboard box | 0.632 | 0.703 | +0.071 | Tiny2 |
| fire | 0.217 | 0.307 | +0.089 | Tiny2 |
| forklift | 0.534 | 0.753 | **+0.219** | Tiny2 |
| freight container | 0.283 | 0.326 | +0.043 | Tiny2 |
| gloves | 0.513 | 0.560 | +0.048 | Tiny2 |
| helmet | 0.669 | 0.716 | +0.048 | Tiny2 |
| ladder | 0.215 | 0.365 | **+0.150** | Tiny2 |
| license plate | 0.330 | 0.373 | +0.043 | Tiny2 |
| person | 0.609 | 0.701 | +0.092 | Tiny2 |
| qr code | 0.820 | 0.823 | +0.002 | Tiny2 |
| road sign | 0.223 | 0.209 | -0.014 | **Tiny1** |
| safety vest | 0.618 | 0.702 | +0.085 | Tiny2 |
| smoke | 0.275 | 0.353 | +0.078 | Tiny2 |
| traffic cone | 0.803 | 0.776 | -0.028 | **Tiny1** |
| traffic light | 0.728 | 0.737 | +0.009 | Tiny2 |
| truck | 0.560 | 0.732 | **+0.171** | Tiny2 |
| van | 0.672 | 0.751 | +0.079 | Tiny2 |
| wood pallet | 0.746 | 0.788 | +0.043 | Tiny2 |

**Key Finding**: Tiny1 outperforms Tiny2 only on 3 classes (barcode, road sign, traffic cone). Tiny2 shows significant improvements (+15-22% AP) on forklift, ladder, and truck detection.

### Overall Performance

| Model | mAP@0.5 |
|:------|--------:|
| yolov4-tiny1 | 0.532 |
| yolov4-tiny2 | **0.589** |

**Recommendation**: YOLOv4-tiny2 is the preferred model for general logistics applications, with 10.7% higher mAP.

### Confidence Threshold Optimization

Model performance varies significantly with confidence threshold selection. The F1 curves demonstrate this for the cardboard box class.

*Generate F1 curves by running `python modules/F1_Curve_and_confusion_matrix.py`:*

<!-- Generated images:
- modules/F1_curve_yolov4-tiny1_cls2.png - Figure 4: Model 1 F1 curve across confidence thresholds
- modules/F1_curve_yolov4-tiny2_cls2.png - Figure 5: Model 2 F1 curve across confidence thresholds
-->

**Insight**: While Tiny1 outperforms Tiny2 at confidence=0.5 for cardboard boxes, Tiny2 achieves superior performance at confidence=0.89. Per-class threshold tuning can optimize application-specific performance.

---

## 3. Robustness Analysis: Data Augmentation Impact

### Augmentation Types Evaluated
- **Gaussian Noise**: Simulates sensor noise and compression artifacts
- **Vertical Flips**: Tests geometric invariance
- **Brightness Adjustment**: Simulates varying lighting conditions

### Results

*Generate augmentation visualizations by running `python modules/augmented_eval_compare.py`:*

<!-- Generated image: modules/viz_out/macro_map_bar.png - Figure 6: mAP comparison across augmentation types -->

| Augmentation | mAP Impact |
|--------------|------------|
| Original (baseline) | 100% |
| Brightness adjustment | ~95% (minor degradation) |
| Vertical flips | ~50% (significant degradation) |
| Gaussian noise | ~50% (significant degradation) |

**Key Findings**:
- Brightness variations have minimal impact on detection performance
- Vertical flips and Gaussian noise reduce performance by approximately 50%
- Model shows good invariance to lighting conditions but is sensitive to geometric and noise perturbations

### Precision-Recall Analysis

<!-- Generated image: modules/viz_out/pr_curves_class_1.png - Figure 7: Precision-Recall curves for car detection under different augmentations -->

---

## 4. Hard Negative Mining Analysis

Hard Negative Mining (HNM) improves model training by focusing on difficult examples. This analysis examines how the λ parameter affects sample selection.

### Impact on Dense Scene Sampling

*Generate HNM analysis plots by running `python modules/rectification/run_hnm_sweep.py`:*

<!-- Generated images (in hnm_out/ directory):
- hnm_negkept_vs_gtbin.png - Figure 8: Negatives retained vs. ground-truth density (sparse → crowded)
- hnm_slope_vs_lambda.png - Figure 9: Sampling concentration trend as λ increases
-->

**Observation**: As λ increases, HNM increasingly concentrates negative sampling on dense scenes. By λ≈10, the highest GT-density bin receives disproportionately more negatives than mid-density bins.

### Impact on Difficult Example Focus

<!-- Generated image: hnm_out/hnm_negkept_vs_fn_bin.png - Figure 10: Negatives retained vs. false negative density -->

**Finding**: With pos_ref=gt, larger λ values push more negatives into images with many false negatives. This targets images where the model currently struggles, potentially improving recall. However, high λ values risk under-sampling sparse/easy images, potentially skewing learning toward crowded cases.

### Recommendations

| λ Value | Use Case |
|---------|----------|
| λ = 1-3 | Balanced sampling across scene densities |
| λ = 5-7 | Moderate focus on difficult cases |
| λ > 10 | Aggressive focus on dense/difficult scenes (use with caution) |

---

## Conclusions

### Model Selection
- **YOLOv4-tiny2** recommended for general logistics applications (mAP: 0.589)
- **YOLOv4-tiny1** may be preferred for specific classes: barcode, road sign, traffic cone

### Robustness Considerations
- Models show strong invariance to brightness changes
- Consider data augmentation with noise and geometric transforms during training to improve robustness

### Hard Negative Mining
- λ parameter should be tuned based on dataset characteristics
- Higher λ improves difficult scene detection but may reduce performance on sparse scenes

### Production Deployment
- Per-class confidence thresholds can optimize application-specific performance
- Monitor for class-specific performance degradation in production
