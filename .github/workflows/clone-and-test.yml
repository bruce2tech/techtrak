name: Manual Grading with Input Parameters

on:
  workflow_dispatch:
    inputs:
      repo_name:
        description: 'Repository URL'
        required: true
      artifact_name:
        required: true
      assignment_num:
        description:  'The assignment number to be graded. Should correspond to the unit testing structure'
        required: true

# declaring all variables that will change
env:
  ORG_NAME: JH-705-603

jobs:
   pull-repo-run-test:
    runs-on: ubuntu-latest
    outputs:
      result: ${{ steps.set_output.outputs.result }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: main

      # Checks-out the student repository under $GITHUB_WORKSPACE, so your job can access it
      - name: Clone student repo
        uses: actions/checkout@v4
        with: 
          repository: '${{ env.ORG_NAME }}/${{ github.event.inputs.repo_name }}'
          path: ${{ github.event.inputs.repo_name }}
          ref: main
      
      - name: setup
        run: |
          # install the python packages for the grading repo
          # pip install -r requirements.txt
          python -m pip install --upgrade pip
          pip install pandas datetime pyarrow timezonefinder flask urllib3

          cd $GITHUB_WORKSPACE
          cp -r ./assignment-${{ github.event.inputs.assignment_num }}-test/* ./${{ github.event.inputs.repo_name }}/techtrack/
          pip install -r ./${{ github.event.inputs.repo_name }}/techtrack/requirements.txt

      # Runs unit test
      - name: Runs all unit tests
        run: |
          cd $GITHUB_WORKSPACE/${{ github.event.inputs.repo_name }}/techtrack/
          python -m unittest -v unit-test.py 2> /home/runner/work/${{ github.event.inputs.artifact_name }} || true

      - name: Save output as artifact
        id: set_output
        uses: actions/upload-artifact@v4
        with:
          name:  ${{ github.event.inputs.artifact_name }}
          path:  /home/runner/work/${{ github.event.inputs.artifact_name }}
